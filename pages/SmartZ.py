import os
import streamlit as st
import google.generativeai as genai
import time

# --- Configuration and Setup ---
st.set_page_config(
    page_title="AI-LAO Chatbot",
    page_icon="ü§ñ",
    layout="centered"
)

# Custom CSS for a modern look
st.markdown(
    """
    <style>
    .stApp {
        background-color: #f3f4f6; /* Light gray background */
        color: #333;
        font-family: 'Phetsarath OT', sans-serif;
        .h1, .h2, .h3 {
            font-family: 'Phetsarath OT', sans-serif;
        }
    }
    .stButton>button {
        background-color: #4CAF50;
        color: white;
        font-weight: bold;
        border-radius: 10px;
        padding: 10px 24px;
        border: none;
        font-family: 'Phetsarath OT', sans-serif;
    }
    .stButton>button:hover {
        background-color: #45a049;
    }
    .chat-container {
        border-radius: 15px;
        padding: 15px;
        background-color: #f3f4f6;
        box-shadow: 0 4px 8px 0 rgba(0,0,0,0.1);
        margin-bottom: 20px;
        font-family: 'Phetsarath OT', sans-serif;
    }
    .user-message {
        background-color: #e0f7fa; /* Light cyan for user messages */
        border-radius: 15px;
        padding: 10px;
        margin-bottom: 10px;
        text-align: right;
        font-family: 'Phetsarath OT', sans-serif;
    }
    .model-message {
        background-color: #f3f4f6; /* Lighter gray for model messages */
        border-radius: 15px;
        padding: 10px;
        margin-bottom: 10px;
        font-family: 'Phetsarath OT', sans-serif;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# Get API key from environment variables
api_key = os.getenv('GOOGLE_API_KEY')
if not api_key:
    st.error("‚ö†Ô∏è **‡ªÄ‡∫Å‡∫µ‡∫î‡∫Ç‡ªç‡ªâ‡∫ú‡∫¥‡∫î‡∫û‡∫≤‡∫î**: ‡∫Å‡∫∞‡∫•‡∫∏‡∫ô‡∫≤‡∫Å‡∫≥‡∫ô‡∫ª‡∫î `GOOGLE_API_KEY` ‡ªÉ‡∫ô environment variables.")
    st.stop()

genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-1.5-flash-latest')

# --- Session State Initialization ---
if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[
        {"role": "model", "parts": ["‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ! ‡∫Ç‡ªâ‡∫≠‡∫ç‡ªÅ‡∫°‡ªà‡∫ô SmartZ ‡∫ç‡∫¥‡∫ô‡∫î‡∫µ‡ªÉ‡∫´‡ªâ‡∫ö‡ªç‡∫•‡∫¥‡∫Å‡∫≤‡∫ô. ‡∫ó‡ªà‡∫≤‡∫ô‡∫°‡∫µ‡∫´‡∫ç‡∫±‡∫á‡∫¢‡∫≤‡∫Å‡∫ñ‡∫≤‡∫°‡∫ö‡ªç‡ªà?"]}
    ])
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- Main UI and Chat Logic ---
st.markdown(
    "<h1 style='text-align: center; color: #4CAF50;'>ü§ñ Chatbot with SmartZ</h1>",
    unsafe_allow_html=True
)
st.markdown(
    "<h3 style='text-align: center; color: #555;'>AI ‡∫ú‡∫π‡ªâ‡∫ä‡ªà‡∫ß‡∫ç‡∫ó‡∫µ‡ªà‡∫û‡ªâ‡∫≠‡∫°‡∫ï‡∫≠‡∫ö‡∫ó‡∫∏‡∫Å‡∫Ñ‡∫≥‡∫ñ‡∫≤‡∫°‡∫Ç‡∫≠‡∫á‡∫ó‡ªà‡∫≤‡∫ô</h3>",
    unsafe_allow_html=True
)

# Display a button to clear chat history
# if st.button("üí¨ ‡ªÄ‡∫•‡∫µ‡ªà‡∫°‡∫Å‡∫≤‡∫ô‡∫™‡∫ª‡∫ô‡∫ó‡∫∞‡∫ô‡∫≤‡ªÉ‡ªù‡ªà"):
#     st.session_state.chat = model.start_chat(history=[
#         {"role": "model", "parts": ["‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ! ‡∫ç‡∫¥‡∫ô‡∫î‡∫µ‡∫ï‡∫≠‡∫ö‡∫Ñ‡∫≥‡∫ñ‡∫≤‡∫°‡∫Ç‡∫≠‡∫á‡∫ó‡ªà‡∫≤‡∫ô."]}
#     ])
#     st.session_state.messages = []
#     st.experimental_rerun()

# --- Display Conversation History ---
# Use a custom message style
for message in st.session_state.messages:
    if message["role"] == "user":
        st.markdown(f"<div class='user-message'>{message['content']}</div>", unsafe_allow_html=True)
    else:
        st.markdown(f"<div class='model-message'>{message['content']}</div>", unsafe_allow_html=True)

# --- Main Chat Input ---
if prompt := st.chat_input("üí¨ ‡∫ñ‡∫≤‡∫°‡∫°‡∫≤‡ªÄ‡∫•‡∫µ‡∫ç! ‡∫Ç‡ªâ‡∫≠‡∫ç‡∫ï‡∫≠‡∫ö‡ªÑ‡∫î‡ªâ‡∫¢‡∫π‡ªà‡ªÅ‡∫•‡ªâ‡∫ß..."):
    # Add user message to display log
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.markdown(f"<div class='user-message'>{prompt}</div>", unsafe_allow_html=True)

    # Get response from the Gemini API
    with st.spinner("‡∫Å‡∫≥‡∫•‡∫±‡∫á‡∫Ñ‡∫¥‡∫î..."):
        try:
            full_response = ""
            message_placeholder = st.empty()
            
            # Use streaming response
            for chunk in st.session_state.chat.send_message(prompt, stream=True):
                full_response += chunk.text
                message_placeholder.markdown(f"<div class='model-message'>{full_response}‚ñå</div>", unsafe_allow_html=True)
            
            message_placeholder.markdown(f"<div class='model-message'>{full_response}</div>", unsafe_allow_html=True)

            # Add model response to display log
            st.session_state.messages.append({"role": "model", "content": full_response})

        except Exception as e:
            st.error(f"‚ùå **‡ªÄ‡∫Å‡∫µ‡∫î‡∫Ç‡ªç‡ªâ‡∫ú‡∫¥‡∫î‡∫û‡∫≤‡∫î**: {e}")